,source,query,query_time,title,journal,authors,doi,published,abstract,url,tags
0,ur,mom,joe,mama,hi,test,jsdfjsd,jksdkjf,jsdfs,jsdf,sdjf
1,arxiv,test,2023-09-20 14:31:51.120996,Heuristic Search for Path Finding with Refuelling,,"['Anushtup Nandy', 'Zhongqiang Ren', 'Sivakumar Rathinam', 'Howie Choset']",,2023-09-19T17:43:11Z,"This paper considers a generalization of the Path Finding (PF) with refueling constraints referred to as the Refuelling Path Finding (RF-PF) problem. Just like PF, the RF-PF problem is defined over a graph, where vertices are gas stations with known fuel prices, and edge costs depend on the gas consumption between the corresponding vertices. RF-PF seeks a minimum-cost path from the start to the goal vertex for a robot with a limited gas tank and a limited number of refuelling stops. While RF-PF is polynomial-time solvable, it remains a challenge to quickly compute an optimal solution in practice since the robot needs to simultaneously determine the path, where to make the stops, and the amount to refuel at each stop. This paper develops a heuristic search algorithm called Refuel A* (RF-A* ) that iteratively constructs partial solution paths from the start to the goal guided by a heuristic function while leveraging dominance rules for state pruning during planning. RF-A* is guaranteed to find an optimal solution and runs more than an order of magnitude faster than the existing state of the art (a polynomial time algorithm) when tested in large city maps with hundreds of gas stations.",http://arxiv.org/abs/2309.10796,"[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T40', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
2,arxiv,test,2023-09-20 14:31:51.120996,"Mobile Manipulation Platform for Autonomous Indoor Inspections in
  Low-Clearance Areas",,"['Erik Pearson', 'Paul Szenher', 'Christine Huang', 'Brendan Englot']",,2023-09-19T17:41:28Z,"Mobile manipulators have been used for inspection, maintenance and repair tasks over the years, but there are some key limitations. Stability concerns typically require mobile platforms to be large in order to handle far-reaching manipulators, or for the manipulators to have drastically reduced workspaces to fit onto smaller mobile platforms. Therefore we propose a combination of two widely-used robots, the Clearpath Jackal unmanned ground vehicle and the Kinova Gen3 six degree-of-freedom manipulator. The Jackal has a small footprint and works well in low-clearance indoor environments. Extensive testing of localization, navigation and mapping using LiDAR sensors makes the Jackal a well developed mobile platform suitable for mobile manipulation. The Gen3 has a long reach with reasonable power consumption for manipulation tasks. A wrist camera for RGB-D sensing and a customizable end effector interface makes the Gen3 suitable for a myriad of manipulation tasks. Typically these features would result in an unstable platform, however with a few minor hardware and software modifications, we have produced a stable, high-performance mobile manipulation platform with significant mobility, reach, sensing, and maneuverability for indoor inspection tasks, without degradation of the component robots' individual capabilities. These assertions were investigated with hardware via semi-autonomous navigation to waypoints in a busy indoor environment, and high-precision self-alignment alongside planar structures for intervention tasks.",http://arxiv.org/abs/2309.10794,"[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
3,arxiv,test,2023-09-20 14:31:51.120996,"Evaluating large language models' ability to understand metaphor and
  sarcasm using a screening test for Asperger syndrome",,['Hiromu Yakura'],,2023-09-19T16:41:19Z,"Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills. However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors. Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder). This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication. The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed. This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been associated with the amygdala, a pivotal cerebral region for emotional learning, in the case of humans.",http://arxiv.org/abs/2309.10744,"[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
4,arxiv,test,2023-09-20 14:31:51.120996,Causality-Driven One-Shot Learning for Prostate Cancer Grading from MRI,,"['Gianluca Carloni', 'Eva Pachetti', 'Sara Colantonio']",,2023-09-19T16:08:33Z,"In this paper, we present a novel method to automatically classify medical images that learns and leverages weak causal signals in the image. Our framework consists of a convolutional neural network backbone and a causality-extractor module that extracts cause-effect relationships between feature maps that can inform the model on the appearance of a feature in one place of the image, given the presence of another feature within some other place of the image. To evaluate the effectiveness of our approach in low-data scenarios, we train our causality-driven architecture in a One-shot learning scheme, where we propose a new meta-learning procedure entailing meta-training and meta-testing tasks that are designed using related classes but at different levels of granularity. We conduct binary and multi-class classification experiments on a publicly available dataset of prostate MRI images. To validate the effectiveness of the proposed causality-driven module, we perform an ablation study and conduct qualitative assessments using class activation maps to highlight regions strongly influencing the network's decision-making process. Our findings show that causal relationships among features play a crucial role in enhancing the model's ability to discern relevant information and yielding more reliable and interpretable predictions. This would make it a promising approach for medical image classification tasks.",http://arxiv.org/abs/2309.10725,"[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2; I.4; I.5; J.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
5,arxiv,test,2023-09-20 14:31:51.120996,"LEA*: An A* Variant Algorithm with Improved Edge Efficiency for Robot
  Motion Planning",,"['Dongliang Zheng', 'Panagiotis Tsiotras']",,2023-09-19T16:04:09Z,"In this work, we introduce a new graph search algorithm, lazy edged based A* (LEA*), for robot motion planning. By using an edge queue and exploiting the idea of lazy search, LEA* is optimally vertex efficient similar to A*, and has improved edge efficiency compared to A*. LEA* is simple and easy to implement with minimum modification to A*, resulting in a very small overhead compared to previous lazy search algorithms. We also explore the effect of inflated heuristics, which results in the weighted LEA* (wLEA*). We show that the edge efficiency of wLEA* becomes close to LazySP and, thus is near-optimal. We test LEA* and wLEA* on 2D planning problems and planning of a 7-DOF manipulator. We perform a thorough comparison with previous algorithms by considering sparse, medium, and cluttered random worlds and small, medium, and large graph sizes. Our results show that LEA* and wLEA* are the fastest algorithms to find the plan compared to previous algorithms.",http://arxiv.org/abs/2309.10722,"[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
6,arxiv,test,2023-09-20 14:31:51.120996,"Modeling electron temperature profiles in the pedestal with simple
  formulas for ETG transport",,"['D. R. Hatch', 'M. T. Kotschenreuther', 'P. -Y. Li', 'B. Chapman-Oplopoiou', 'J. Parisi', 'S. M. Mahajan', 'R. Groebner']",,2023-09-19T15:54:16Z,"This paper reports on the refinement (building on Ref.~\cite{hatch_22}) and application of simple formulas for electron heat transport from electron temperature gradient (ETG) driven turbulence in the pedestal. The formulas are improved by (1) improving the parameterization for certain key parameters and (2) carefully accounting for the impact of geometry and shaping in the underlying gyrokinetic simulation database. Comparisons with nonlinear gyrokinetic simulations of ETG transport in the MAST pedestal demonstrate the model's applicability to spherical tokamaks in addition to standard aspect ratio tokamaks. We identify bounds for model applicability: the model is accurate in the steep gradient region, where the ETG turbulence is largely slab-like, but accuracy decreases as the temperature gradient becomes weaker in the pedestal top and the instabilities become increasingly toroidal in nature. We use the formula to model the electron temperature profile in the pedestal for four experimental scenarios while extensively varying input parameters to represent uncertainties. In all cases, the predicted electron temperature pedestal exhibits extreme sensitivity to separatrix temperature and density, which has implications for core-edge integration. The model reproduces the electron temperature profile for high $\eta_e = L_{ne}/L_{Te}$ scenarios but not for low $\eta_e$ scenarios in which microtearing modes have been identified. We develop a proof-of-concept model for MTM transport and explore the relative roles of ETG and MTM in setting the electron temperature profile. We propose that pedestal scenarios predicted for future devices should be tested for compatibility with ETG transport.",http://arxiv.org/abs/2309.10708,"[{'term': 'physics.plasm-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
7,arxiv,test,2023-09-20 14:31:51.120996,Nested Gausslet Basis Sets,,"['Steven R. White', 'Michael J. Lindsey']",,2023-09-19T15:44:53Z,"We introduce nested gausslet (NG) bases, an improvement on previous gausslet bases which can treat systems containing atoms with much larger atomic number. We also introduce pure Gaussian distorted gausslet bases, which allow the Hamiltonian integrals to be performed analytically, as well as hybrid bases in which the gausslets are combined with standard Gaussian-type bases. All these bases feature the diagonal approximation for the electron-electron interactions, so that the Hamiltonian is completely defined by two $N_b\times N_b$ matrices, where $N_b \approx 10^4$ is small enough to permit fast calculations at the Hartree-Fock level. In constructing these bases we have gained new mathematical insight into the construction of one-dimensional diagonal bases. In particular we have proved an important theorem relating four key basis set properties: completeness, orthogonality, zero-moment conditions, and diagonalization of the coordinate operator matrix. We test our basis sets on small systems with a focus on high accuracy, obtaining, for example, an accuracy of $2\times10^{-5}$ Ha for the total Hartree-Fock energy of the neon atom in the complete basis set limit.",http://arxiv.org/abs/2309.10704,"[{'term': 'physics.chem-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.str-el', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.atom-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.comp-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
8,arxiv,test,2023-09-20 14:31:51.120996,"Improved Nonnegativity Testing in the Bernstein Basis via Geometric
  Means",,"['Mitchell Tong Harris', 'Pablo A. Parrilo']",,2023-09-19T14:58:02Z,"We develop a new kind of nonnegativity certificate for univariate polynomials on an interval. In many applications, nonnegative Bernstein coefficients are often used as a simple way of certifying polynomial nonnegativity. Our proposed condition is instead an explicit lower bound for each Bernstein coefficient in terms of the geometric mean of its adjacent coefficients, which is provably less restrictive than the usual test based on nonnegative coefficients. We generalize to matrix-valued polynomials of arbitrary degree, and we provide numerical experiments suggesting the practical benefits of this condition. The techniques for constructing this inexpensive certificate could potentially be applied to other semialgebraic feasibility problems.",http://arxiv.org/abs/2309.10675,"[{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
9,arxiv,test,2023-09-20 14:31:51.120996,"CloudSimSC: A Toolkit for Modeling and Simulation of Serverless
  Computing Environments",,"['Anupama Mampage', 'Rajkumar Buyya']",,2023-09-19T14:54:07Z,"Serverless computing is gaining traction as an attractive model for the deployment of a multitude of workloads in the cloud. Designing and building effective resource management solutions for any computing environment requires extensive long term testing, experimentation and analysis of the achieved performance metrics. Utilizing real test beds and serverless platforms for such experimentation work is often times not possible due to resource, time and cost constraints. Thus, employing simulators to model these environments is key to overcoming the challenge of examining the viability of such novel ideas for resource management. Existing simulation software developed for serverless environments lack generalizibility in terms of their architecture as well as the various aspects of resource management, where most are purely focused on modeling function performance under a specific platform architecture. In contrast, we have developed a serverless simulation model with induced flexibility in its architecture as well as the key resource management aspects of function scheduling and scaling. Further, we incorporate techniques for easily deriving monitoring metrics required for evaluating any implemented solutions by users. Our work is presented as CloudSimSC, a modular extension to CloudSim which is a simulator tool extensively used for modeling cloud environments by the research community. We discuss the implemented features in our simulation tool using multiple use cases.",http://arxiv.org/abs/2309.10671,"[{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
10,arxiv,test,2023-09-20 14:31:51.120996,"Testing and correcting sample selection in academic achievement
  comparisons",,['Onil Boussim'],,2023-09-19T14:22:26Z,"Country comparisons using standardized test scores may in some cases be misleading unless we make sure that the potential sample selection bias created by drop-outs and non-enrollment patterns does not alter the analysis. In this paper, I propose an answer to this issue which consists in comparing the counterfactual distribution of achievement (I mean the distribution of achievement if there was hypothetically no selection) and the observed distribution of achievements. If the difference is statistically significant, international comparison measures like means, quantiles, and inequality measures have to be computed using that counterfactual distribution. I identify the quantiles of that latent distribution by readjusting the percentile levels of the observed quantile function of achievement. Because the data on test scores is by nature truncated, I have to rely on auxiliary data to borrow identification power. I finally applied my method to 6 sub-Saharan countries using 6th-grade test scores.",http://arxiv.org/abs/2309.10642,"[{'term': 'econ.EM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
11,arxiv,test,2023-09-20 14:31:51.120996,"To clump or not to clump The impact of wind inhomogeneities on the
  optical and NIR spectroscopic analysis of massive OB stars",,"['K. Rübke', 'A. Herrero', 'J. Puls']",,2023-09-19T13:45:39Z,"Winds of massive stars have density inhomogeneities (clumping) that may affect the formation of spectral lines in different ways, depending on their formation region. Most of previous and current spectroscopic analyses have been performed in the optical or ultraviolet domain. However, massive stars are often hidden behind dense clouds rendering near-infrared observations necessary. Our objective is to investigate whether a spectroscopic analysis using either optical or infrared observations results in the same stellar parameters with comparable accuracy, and whether clumping affects them in different ways. We analyzed optical and near-infrared observations of a set of massive O stars with spectral types O4-O9.5 and all luminosity classes. We obtain similar stellar parameters in the optical and the infrared, although with larger uncertainties in the near-infrared, both with and without clumping, albeit with some individual deviating cases. We find that the inclusion of clumping improves the fit to H$_\alpha$ or HeII 4686 in the optical for supergiants, as well as that of Br$_\gamma$ in the near-infrared, but it sometimes worsens the fit to HeII 2.18$\mu$m. Globally, there are no significant differences when using the clumping laws tested in this work. The infrared can be used for spectroscopic analyses, giving similar parameters as from the optical, though with larger uncertainties. The best fits to different lines are obtained with different (linear) clumping laws, indicating that the wind structure may be more complex than adopted in the present work. No clumping law results in a better global fit, or improves the consistency between optical and infrared stellar parameters. Our work shows that the optical and infrared lines are not sufficient to break the dichotomy between the mass-loss rate and clumping factor.",http://arxiv.org/abs/2309.10615,"[{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'astro-ph.GA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
12,arxiv,test,2023-09-20 14:31:51.120996,A New Bootstrap Goodness-of-Fit Test for Normal Linear Regression Models,,"['Scott H. Koeneman', 'Joseph E. Cavanaugh']",,2023-09-19T13:43:36Z,"In this work, the distributional properties of the goodness-of-fit term in likelihood-based information criteria are explored. These properties are then leveraged to construct a novel goodness-of-fit test for normal linear regression models that relies on a non-parametric bootstrap. Several simulation studies are performed to investigate the properties and efficacy of the developed procedure, with these studies demonstrating that the bootstrap test offers distinct advantages as compared to other methods of assessing the goodness-of-fit of a normal linear regression model.",http://arxiv.org/abs/2309.10614,"[{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
13,arxiv,test,2023-09-20 14:31:51.120996,An Extendable Python Implementation of Robust Optimisation Monte Carlo,,"['Vasilis Gkolemis', 'Michael Gutmann', 'Henri Pesonen']",,2023-09-19T13:37:47Z,"Performing inference in statistical models with an intractable likelihood is challenging, therefore, most likelihood-free inference (LFI) methods encounter accuracy and efficiency limitations. In this paper, we present the implementation of the LFI method Robust Optimisation Monte Carlo (ROMC) in the Python package ELFI. ROMC is a novel and efficient (highly-parallelizable) LFI framework that provides accurate weighted samples from the posterior. Our implementation can be used in two ways. First, a scientist may use it as an out-of-the-box LFI algorithm; we provide an easy-to-use API harmonized with the principles of ELFI, enabling effortless comparisons with the rest of the methods included in the package. Additionally, we have carefully split ROMC into isolated components for supporting extensibility. A researcher may experiment with novel method(s) for solving part(s) of ROMC without reimplementing everything from scratch. In both scenarios, the ROMC parts can run in a fully-parallelized manner, exploiting all CPU cores. We also provide helpful functionalities for (i) inspecting the inference process and (ii) evaluating the obtained samples. Finally, we test the robustness of our implementation on some typical LFI examples.",http://arxiv.org/abs/2309.10612,"[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
14,arxiv,test,2023-09-20 14:31:51.120996,Asteroids co-orbital motion classification based on Machine Learning,,"['Giulia Ciacci', 'Andrea Barucci', 'Sara Di Ruzza', 'Elisa Maria Alessi']",,2023-09-19T13:19:31Z,"In this work, we explore how to classify asteroids in co-orbital motion with a given planet using Machine Learning. We consider four different kinds of motion in mean motion resonance with the planet, nominally Tadpole, Horseshoe and Quasi-satellite, building 3 datasets defined as Real (taking the ephemerides of real asteroids from the JPL Horizons system), Ideal and Perturbed (both simulated, obtained by propagating initial conditions considering two different dynamical systems) for training and testing the Machine Learning algorithms in different conditions.   The time series of the variable theta (angle related to the resonance) are studied with a data analysis pipeline defined ad hoc for the problem and composed by: data creation and annotation, time series features extraction thanks to the tsfresh package (potentially followed by selection and standardization) and the application of Machine Learning algorithms for Dimensionality Reduction and Classification. Such approach, based on features extracted from the time series, allows to work with a smaller number of data with respect to Deep Learning algorithms, also allowing to define a ranking of the importance of the features. Physical Interpretability of the features is another key point of this approach. In addition, we introduce the SHapley Additive exPlanations for Explainability technique.   Different training and test sets are used, in order to understand the power and the limits of our approach. The results show how the algorithms are able to identify and classify correctly the time series, with a high degree of performance.",http://arxiv.org/abs/2309.10603,"[{'term': 'astro-ph.EP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
15,arxiv,test,2023-09-20 14:31:51.120996,"TELESIM: A Modular and Plug-and-Play Framework for Robotic Arm
  Teleoperation using a Digital Twin",,"['Audonnet P Florent', 'Jonathan Grizou', 'Andrew Hamilton', 'Gerardo Aragon-Camarasa']",,2023-09-19T12:38:28Z,"We present TELESIM, a modular and plug-and-play framework for direct teleoperation of a robotic arm using a digital twin as the interface between the user and the robotic system. We tested TELESIM by performing a user survey with 37 participants on two different robots using two different control modalities: a virtual reality controller and a finger mapping hardware controller using different grasping systems. Users were asked to teleoperate the robot to pick and place 3 cubes in a tower and to repeat this task as many times as possible in 10 minutes, with only 5 minutes of training beforehand. Our experimental results show that most users were able to succeed by building at least a tower of 3 cubes regardless of the control modality or robot used, demonstrating the user-friendliness of TELESIM.",http://arxiv.org/abs/2309.10579,"[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
16,arxiv,test,2023-09-20 14:31:51.120996,"A Cognitively-Inspired Neural Architecture for Visual Abstract Reasoning
  Using Contrastive Perceptual and Conceptual Processing",,"['Yuan Yang', 'Deepayan Sanyal', 'James Ainooson', 'Joel Michelson', 'Effat Farhana', 'Maithilee Kunda']",,2023-09-19T11:18:01Z,"We introduce a new neural architecture for solving visual abstract reasoning tasks inspired by human cognition, specifically by observations that human abstract reasoning often interleaves perceptual and conceptual processing as part of a flexible, iterative, and dynamic cognitive process. Inspired by this principle, our architecture models visual abstract reasoning as an iterative, self-contrasting learning process that pursues consistency between perceptual and conceptual processing of visual stimuli. We explain how this new Contrastive Perceptual-Conceptual Network (CPCNet) works using matrix reasoning problems in the style of the well-known Raven's Progressive Matrices intelligence test. Experiments on the machine learning dataset RAVEN show that CPCNet achieves higher accuracy than all previously published models while also using the weakest inductive bias. We also point out a substantial and previously unremarked class imbalance in the original RAVEN dataset, and we propose a new variant of RAVEN -- AB-RAVEN -- that is more balanced in terms of abstract concepts.",http://arxiv.org/abs/2309.10532,"[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
17,arxiv,test,2023-09-20 14:31:51.120996,"Spatial-Assistant Encoder-Decoder Network for Real Time Semantic
  Segmentation",,"['Yalun Wang', 'Shidong Chen', 'Huicong Bian', 'Weixiao Li', 'Qin Lu']",,2023-09-19T10:59:42Z,"Semantic segmentation is an essential technology for self-driving cars to comprehend their surroundings. Currently, real-time semantic segmentation networks commonly employ either encoder-decoder architecture or two-pathway architecture. Generally speaking, encoder-decoder models tend to be quicker,whereas two-pathway models exhibit higher accuracy. To leverage both strengths, we present the Spatial-Assistant Encoder-Decoder Network (SANet) to fuse the two architectures. In the overall architecture, we uphold the encoder-decoder design while maintaining the feature maps in the middle section of the encoder and utilizing atrous convolution branches for same-resolution feature extraction. Toward the end of the encoder, we integrate the asymmetric pooling pyramid pooling module (APPPM) to optimize the semantic extraction of the feature maps. This module incorporates asymmetric pooling layers that extract features at multiple resolutions. In the decoder, we present a hybrid attention module, SAD, that integrates horizontal and vertical attention to facilitate the combination of various branches. To ascertain the effectiveness of our approach, our SANet model achieved competitive results on the real-time CamVid and cityscape datasets. By employing a single 2080Ti GPU, SANet achieved a 78.4 % mIOU at 65.1 FPS on the Cityscape test dataset and 78.8 % mIOU at 147 FPS on the CamVid test dataset. The training code and model for SANet are available at https://github.com/CuZaoo/SANet-main",http://arxiv.org/abs/2309.10519,"[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
18,arxiv,test,2023-09-20 14:31:51.120996,Partially-Specified Causal Simulations,,"['A. Zamanian', 'L. Mareis', 'N. Ahmidi']",,2023-09-19T10:50:35Z,"Simulation studies play a key role in the validation of causal inference methods. The simulation results are reliable only if the study is designed according to the promised operational conditions of the method-in-test. Still, many causal inference literature tend to design over-restricted or misspecified studies. In this paper, we elaborate on the problem of improper simulation design for causal methods and compile a list of desiderata for an effective simulation framework. We then introduce partially-randomized causal simulation (PARCS), a simulation framework that meets those desiderata. PARCS synthesizes data based on graphical causal models and a wide range of adjustable parameters. There is a legible mapping from usual causal assumptions to the parameters, thus, users can identify and specify the subset of related parameters and randomize the remaining ones to generate a range of complying data-generating processes for their causal method. The result is a more comprehensive and inclusive empirical investigation for causal claims. Using PARCS, we reproduce and extend the simulation studies of two well-known causal discovery and missing data analysis papers to emphasize the necessity of a proper simulation design. Our results show that those papers would have improved and extended the findings, had they used PARCS for simulation. The framework is implemented as a Python package, too. By discussing the comprehensiveness and transparency of PARCS, we encourage causal inference researchers to utilize it as a standard tool for future works.",http://arxiv.org/abs/2309.10514,"[{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
19,arxiv,test,2023-09-20 14:31:51.121997,Fully automated landmarking and facial segmentation on 3D photographs,,"['Bo Berends', 'Freek Bielevelt', 'Ruud Schreurs', 'Shankeeth Vinayahalingam', 'Thomas Maal', 'Guido de Jong']",,2023-09-19T09:39:55Z,"Three-dimensional facial stereophotogrammetry provides a detailed representation of craniofacial soft tissue without the use of ionizing radiation. While manual annotation of landmarks serves as the current gold standard for cephalometric analysis, it is a time-consuming process and is prone to human error. The aim in this study was to develop and evaluate an automated cephalometric annotation method using a deep learning-based approach. Ten landmarks were manually annotated on 2897 3D facial photographs by a single observer. The automated landmarking workflow involved two successive DiffusionNet models and additional algorithms for facial segmentation. The dataset was randomly divided into a training and test dataset. The training dataset was used to train the deep learning networks, whereas the test dataset was used to evaluate the performance of the automated workflow. The precision of the workflow was evaluated by calculating the Euclidean distances between the automated and manual landmarks and compared to the intra-observer and inter-observer variability of manual annotation and the semi-automated landmarking method. The workflow was successful in 98.6% of all test cases. The deep learning-based landmarking method achieved precise and consistent landmark annotation. The mean precision of 1.69 (+/-1.15) mm was comparable to the inter-observer variability (1.31 +/-0.91 mm) of manual annotation. The Euclidean distance between the automated and manual landmarks was within 2 mm in 69%. Automated landmark annotation on 3D photographs was achieved with the DiffusionNet-based approach. The proposed method allows quantitative analysis of large datasets and may be used in diagnosis, follow-up, and virtual surgical planning.",http://arxiv.org/abs/2309.10472,"[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
20,arxiv,test,2023-09-20 14:31:51.121997,"Exoplanet imaging with ELTs: exploring a second-stage AO with a Zernike
  wavefront sensor on the ESO/GHOST testbed",,"[""Mamadou N'Diaye"", 'Arthur Vigan', 'Byron Engler', 'Markus Kasper', 'Serban Leveratto', 'Johan Floriot', 'Michel Marcos', 'Christophe Bailet', 'Kjetil Dohlen']",,2023-09-19T09:33:40Z,"We propose to explore a cascade extreme Adaptive optics (ExAO) approach with a second stage based on a Zernike wavefront sensor (ZWFS) for exoplanet imaging and spectroscopy. Most exoplanet imagers currently use a single-stage ExAO to correct for the effects of atmospheric turbulence and produce high-Strehl images of observed stars in the near-infrared. While such systems enable the observation of warm gaseous companions around nearby stars, adding a second-stage AO enables to push the wavefront correction further and possibly observe colder or smaller planets. This approach is currently investigated in different exoplanet imagers (VLT/SPHERE, Mag-AOX, Subaru/SCExAO) by considering a Pyramid wavefront sensor (PWFS) in the second arm to measure the residual atmospheric turbulence left from the first stage. Since these aberrations are expected to be very small (a few tens of nm in the near-infrared domain), we propose to investigate an alternative approach based on the ZWFS. This sensor is a promising concept with a small capture range to estimate residual wavefront errors thanks to its large sensitivity, simple phase reconstruction and easiness of implementation. In this contribution, we perform preliminary tests on the GHOST testbed at ESO to validate this approach experimentally. Additional experiments with petalling effects are also showed, giving promising wavefront correction results. Finally, we briefly discuss a first comparison between PWFS-based and ZWFS-based second-stage AO to draw preliminary conclusions on the interests of both schemes for exoplanet imaging and spectroscopy with the upgrade of the current exoplanet imagers and the envisioned ExAO instruments for ELTs.",http://arxiv.org/abs/2309.10465,"[{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'astro-ph.EP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
21,arxiv,test,2023-09-20 14:31:51.121997,"Posterior sampling algorithms for unsupervised speech enhancement with
  recurrent variational autoencoder",,"['Mostafa Sadeghi', 'Romain Serizel']",,2023-09-19T08:59:32Z,"In this paper, we address the unsupervised speech enhancement problem based on recurrent variational autoencoder (RVAE). This approach offers promising generalization performance over the supervised counterpart. Nevertheless, the involved iterative variational expectation-maximization (VEM) process at test time, which relies on a variational inference method, results in high computational complexity. To tackle this issue, we present efficient sampling techniques based on Langevin dynamics and Metropolis-Hasting algorithms, adapted to the EM-based speech enhancement with RVAE. By directly sampling from the intractable posterior distribution within the EM process, we circumvent the intricacies of variational inference. We conduct a series of experiments, comparing the proposed methods with VEM and a state-of-the-art supervised speech enhancement approach based on diffusion models. The results reveal that our sampling-based algorithms significantly outperform VEM, not only in terms of computational efficiency but also in overall performance. Furthermore, when compared to the supervised baseline, our methods showcase robust generalization performance in mismatched test conditions.",http://arxiv.org/abs/2309.10439,"[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
22,arxiv,test,2023-09-20 14:31:51.121997,"Functional requirements to mitigate the Risk of Harm to Patients from
  Artificial Intelligence in Healthcare",,"['Juan M. García-Gómez', 'Vicent Blanes-Selva', 'José Carlos de Bartolomé Cenzano', 'Jaime Cebolla-Cornejo', 'Ascensión Doñate-Martínez']",,2023-09-19T08:37:22Z,"The Directorate General for Parliamentary Research Services of the European Parliament has prepared a report to the Members of the European Parliament where they enumerate seven main risks of Artificial Intelligence (AI) in medicine and healthcare: patient harm due to AI errors, misuse of medical AI tools, bias in AI and the perpetuation of existing inequities, lack of transparency, privacy and security issues, gaps in accountability, and obstacles in implementation.   In this study, we propose fourteen functional requirements that AI systems may implement to reduce the risks associated with their medical purpose: AI passport, User management, Regulation check, Academic use only disclaimer, data quality assessment, Clinicians double check, Continuous performance evaluation, Audit trail, Continuous usability test, Review of retrospective/simulated cases, Bias check, eXplainable AI, Encryption and use of field-tested libraries, and Semantic interoperability.   Our intention here is to provide specific high-level specifications of technical solutions to ensure continuous good performance and use of AI systems to benefit patients in compliance with the future EU regulatory framework.",http://arxiv.org/abs/2309.10424,"[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
23,arxiv,test,2023-09-20 14:31:51.121997,Graph Neural Networks for Dynamic Modeling of Roller Bearing,,"['Vinay Sharma', 'Jens Ravesloot', 'Cees Taal', 'Olga Fink']",,2023-09-19T08:30:10Z,"In the presented work, we propose to apply the framework of graph neural networks (GNNs) to predict the dynamics of a rolling element bearing. This approach offers generalizability and interpretability, having the potential for scalable use in real-time operational digital twin systems for monitoring the health state of rotating machines. By representing the bearing's components as nodes in a graph, the GNN can effectively model the complex relationships and interactions among them. We utilize a dynamic spring-mass-damper model of a bearing to generate the training data for the GNN. In this model, discrete masses represent bearing components such as rolling elements, inner raceways, and outer raceways, while a Hertzian contact model is employed to calculate the forces between these components.   We evaluate the learning and generalization capabilities of the proposed GNN framework by testing different bearing configurations that deviate from the training configurations. Through this approach, we demonstrate the effectiveness of the GNN-based method in accurately predicting the dynamics of rolling element bearings, highlighting its potential for real-time health monitoring of rotating machinery.",http://arxiv.org/abs/2309.10418,"[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
24,arxiv,test,2023-09-20 14:31:51.121997,"Characterization of SiPM and development of test bench modules for the
  next-generation cameras for Large-Sized Telescopes for Cherenkov Telescope
  Array",,"['Takayuki. Saito', 'K. Hashiyama', 'H. Iwasaki', 'H. Kubo', 'M. Mizote', 'A. Okumura', 'H. Tajima', 'T. Yamamoto']",,2023-09-19T08:22:20Z,"The recent improvements in the performance of the silicon photomultipliers (SiPMs) made them attractive options as photo sensors of imaging atmospheric Cherenkov telescopes (IACTs). In fact, they are already adopted in some IACTs such as FACT and the Small-Sized Telescopes of the Cherenkov Telescope Array (CTA). However, the application to the Large-Sized Telescopes (LSTs) of CTA requires additional studies. As the pixel size of LSTs is larger than the nominal size of SiPMs, the signal from multiple sensors must be summed up. Also, the high detection efficiency of the night sky background (NSB) photons may degrade the telescope performance. To overcome this, the pulse width must be as small as 3 ns and the detection efficiency for NSB photons must be suppressed as much as possible. Heat generation and gain stabilization are also issues. We studied different types of SiPMs from Hamamatsu photonics and characterized them for the LST application, addressing the previous points. Also, to prove the SiPM performance in LST, we are developing a SiPM module which can be installed in the exisiting LST camera. Here we present the results of this evaluation and the status of the test bench module development.",http://arxiv.org/abs/2309.10411,"[{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'astro-ph.HE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
25,arxiv,test,2023-09-20 14:31:51.121997,Augmenting Tactile Simulators with Real-like and Zero-Shot Capabilities,,"['Osher Azulay', 'Alon Mizrahi', 'Nimrod Curtis', 'Avishai Sintov']",,2023-09-19T08:19:01Z,"Simulating tactile perception could potentially leverage the learning capabilities of robotic systems in manipulation tasks. However, the reality gap of simulators for high-resolution tactile sensors remains large. Models trained on simulated data often fail in zero-shot inference and require fine-tuning with real data. In addition, work on high-resolution sensors commonly focus on ones with flat surfaces while 3D round sensors are essential for dexterous manipulation. In this paper, we propose a bi-directional Generative Adversarial Network (GAN) termed SightGAN. SightGAN relies on the early CycleGAN while including two additional loss components aimed to accurately reconstruct background and contact patterns including small contact traces. The proposed SightGAN learns real-to-sim and sim-to-real processes over difference images. It is shown to generate real-like synthetic images while maintaining accurate contact positioning. The generated images can be used to train zero-shot models for newly fabricated sensors. Consequently, the resulted sim-to-real generator could be built on top of the tactile simulator to provide a real-world framework. Potentially, the framework can be used to train, for instance, reinforcement learning policies of manipulation tasks. The proposed model is verified in extensive experiments with test data collected from real sensors and also shown to maintain embedded force information within the tactile images.",http://arxiv.org/abs/2309.10409,"[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
